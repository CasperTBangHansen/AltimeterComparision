{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, NamedTuple, Iterable, Hashable\n",
    "from datetime import date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "from tqdm import tqdm\n",
    "from plotting import date_to_processed, make_png\n",
    "\n",
    "CMEMS_PATH = Path(r\"C:\\Users\\Casper\\OneDrive - Danmarks Tekniske Universitet\\SKOLE\\Kandidat\\Syntese\\ProcessedGrids\\CMEMS_2019_old\")\n",
    "MEASURES_PATH = Path(r\"C:\\Users\\Casper\\OneDrive - Danmarks Tekniske Universitet\\SKOLE\\Kandidat\\Syntese\\ProcessedGrids\\MEaSUREs\")\n",
    "PROCESSED = Path(r\"C:\\Users\\Casper\\OneDrive - Danmarks Tekniske Universitet\\SKOLE\\Kandidat\\Syntese\\ProcessedGrids\\v5\")\n",
    "RAW = Path(r\"C:\\Users\\Casper\\Desktop\\day_data\\Processed_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedFiles(NamedTuple):\n",
    "    Date: date\n",
    "    Measures: Path | None\n",
    "    Cmems: Path | None\n",
    "    Processed: Path\n",
    "\n",
    "    @property\n",
    "    def ContainsMeasures(self):\n",
    "        return self.Measures is not None\n",
    "    \n",
    "    @property\n",
    "    def ContainsCmems(self):\n",
    "        return self.Cmems is not None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        repr_str = f\"{self.Date}, {self.Processed.name}\"\n",
    "        if self.Measures is not None:\n",
    "            repr_str += f\", {self.Measures.name}\"\n",
    "        if self.Cmems is not None:\n",
    "            repr_str += f\", {self.Cmems.name}\"\n",
    "        return f\"MatchedFiles({repr_str})\"\n",
    "\n",
    "\n",
    "class MatchedData(NamedTuple):\n",
    "    Files: MatchedFiles\n",
    "    Cmems: xr.Dataset | None\n",
    "    Processed: xr.Dataset\n",
    "    Measures: xr.Dataset | None\n",
    "\n",
    "    @property\n",
    "    def Date(self):\n",
    "        return self.Files.Date\n",
    "\n",
    "    @property\n",
    "    def ContainsMeasures(self):\n",
    "        return self.Measures is not None\n",
    "    \n",
    "    @property\n",
    "    def ContainsCmems(self):\n",
    "        return self.Cmems is not None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        repr_str = f\"{self.Date}, Processed[Grid]\"\n",
    "        if self.ContainsMeasures:\n",
    "            repr_str += \", Measures[Grid]\"\n",
    "        if self.ContainsCmems:\n",
    "            repr_str += \", Cmems[Grid]\"\n",
    "        return f\"MatchedData({repr_str})\"\n",
    "\n",
    "def get_dims(data: xr.Dataset, keys: Iterable[Hashable], subtract: Iterable[float]) -> xr.DataArray | None:\n",
    "    for key, sub in zip(keys, subtract):\n",
    "        if key in data.coords:\n",
    "            return data[key] - sub\n",
    "    return None\n",
    "\n",
    "def get_extent(data: xr.Dataset) -> Tuple[float, float, float, float]:\n",
    "    lat = get_dims(data, ['latitude', 'Latitude'], [0, 0])\n",
    "    lon = get_dims(data, ['longitude', 'Longitude'], [180, 0])\n",
    "    if lat is None or lon is None:\n",
    "        raise ValueError(f\"data does not contain either a valid dimension\")\n",
    "\n",
    "    return (\n",
    "        lon.min().item(),\n",
    "        lon.max().item(),\n",
    "        lat.min().item(),\n",
    "        lat.max().item()\n",
    "    )\n",
    "\n",
    "def rotate_data(data: xr.DataArray, coord: str, upper_boundary: float):\n",
    "    new_data = np.empty(data.shape)\n",
    "    # Assign lower bound\n",
    "    bool_arr = data[coord] < upper_boundary\n",
    "    new_data[:, ~bool_arr] = data.isel(**{coord: bool_arr})\n",
    "    new_data[:, bool_arr] = data.isel(**{coord: ~bool_arr})\n",
    "    return new_data\n",
    "\n",
    "def bin_ndarray(ndarray, new_shape, operation='sum'):\n",
    "    \"\"\"\n",
    "    Bins an ndarray in all axes based on the target shape, by summing or averaging.\n",
    "    Number of output dimensions must match number of input dimensions.\n",
    "    \"\"\"\n",
    "    if not operation.lower() in ['sum', 'mean', 'average', 'avg']:\n",
    "        raise ValueError(\"Operation {} not supported.\".format(operation))\n",
    "    if ndarray.ndim != len(new_shape):\n",
    "        raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape, new_shape))\n",
    "    compression_pairs = [(d, c//d) for d, c in zip(new_shape, ndarray.shape)]\n",
    "    flattened = [l for p in compression_pairs for l in p]\n",
    "    ndarray = ndarray.reshape(flattened)\n",
    "    for i in range(len(new_shape)):\n",
    "        if operation.lower() == \"sum\":\n",
    "            ndarray = ndarray.sum(-1*(i+1))\n",
    "        elif operation.lower() in [\"mean\", \"average\", \"avg\"]:\n",
    "            ndarray = ndarray.mean(-1*(i+1))\n",
    "    return ndarray\n",
    "\n",
    "def processed_to_date(file: Path) -> date:\n",
    "    year, month, day = file.name.replace('.nc', '').split('_')\n",
    "    return date(int(year), int(month), int(day))\n",
    "\n",
    "def cmems_to_date(file: Path) -> date:\n",
    "    cleaned_filename = file.name.replace('.nc', '').replace('dt_global_allsat_phy_l4_', '')\n",
    "    date_name = cleaned_filename.split('_')[0]\n",
    "    return date(int(date_name[:4]), int(date_name[4:6]), int(date_name[6:]))\n",
    "\n",
    "def measures_to_date(file: Path) -> date:\n",
    "    date_name = file.name.replace('.nc', '').replace('ssh_grids_v2205_', '')\n",
    "    return date(int(date_name[:4]), int(date_name[4:6]), int(date_name[6:8]))\n",
    "\n",
    "def match_files(processed: Path, cmems: Path, measures: Path, processed_glob: str = '*.nc') -> List[MatchedFiles]:\n",
    "    cmems_files = list(cmems.glob('*.nc'))\n",
    "    measures_files = list(measures.glob('*.nc'))\n",
    "    processed_files = list(processed.glob(processed_glob))\n",
    "    cmems_dates = [cmems_to_date(f) for f in cmems_files]\n",
    "    measures_dates = [measures_to_date(f) for f in measures_files]\n",
    "    processed_dates = [processed_to_date(f) for f in processed_files]\n",
    "\n",
    "    matchedFilesList = []\n",
    "    for p_date, file in zip(processed_dates, processed_files):\n",
    "        cmems_date, measures_date = None, None\n",
    "        if p_date in cmems_dates:\n",
    "            cmems_date = cmems_files[cmems_dates.index(p_date)]\n",
    "        if p_date in measures_dates:\n",
    "            measures_date = measures_files[measures_dates.index(p_date)]\n",
    "        matchedFilesList.append(MatchedFiles(p_date, measures_date, cmems_date, file))\n",
    "    matchedFilesList = sorted(matchedFilesList, key = lambda x: x.Date)\n",
    "    return matchedFilesList\n",
    "\n",
    "def load_raw(folder: Path, file_date: date, n_days: int) -> xr.Dataset:\n",
    "    files = []\n",
    "    for day in range(-n_days, n_days + 1):\n",
    "        curent_day = file_date + timedelta(days=day)\n",
    "        files.append(folder / Path(f\"{curent_day.year}_{curent_day.month}_{curent_day.day}.nc\"))\n",
    "    return xr.open_mfdataset(files, concat_dim='time', combine='nested', engine='netcdf4')\n",
    "\n",
    "def load_file(file: MatchedFiles) -> MatchedData:\n",
    "    cmems, measures = None, None\n",
    "    processed = xr.open_dataset(file.Processed)\n",
    "    if file.ContainsCmems:\n",
    "        cmems = xr.open_dataset(file.Cmems) # type: ignore\n",
    "    if file.Measures:\n",
    "        measures = xr.open_dataset(file.Measures) # type: ignore\n",
    "    return MatchedData(file, cmems, processed, measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_paths = match_files(PROCESSED, CMEMS_PATH, MEASURES_PATH, '2019_1_2.nc')\n",
    "data = {matched_path.Date: load_file(matched_path) for matched_path in matched_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CMEMS\n",
      "Found MEaSUREs\n"
     ]
    }
   ],
   "source": [
    "n_days = [5, 3, 1]\n",
    "plot_date = list(data)[0]\n",
    "\n",
    "processed = data[plot_date].Processed\n",
    "if (cmems := data[plot_date].Cmems) is None:\n",
    "    binned_cmems = None\n",
    "else:\n",
    "    new_cmems = rotate_data(cmems.sla[0], 'longitude', 180)\n",
    "    new_shape = (180, 360)\n",
    "    lat_frac = new_cmems.shape[0]/new_shape[0]\n",
    "    lon_frac = new_cmems.shape[1]/new_shape[1]\n",
    "    binned_cmems = bin_ndarray(new_cmems, new_shape, operation='mean')\n",
    "    print(\"Found CMEMS\")\n",
    "\n",
    "if (measures := data[plot_date].Measures) is None:\n",
    "    binned_measures = None\n",
    "else:\n",
    "    new_measures = rotate_data(measures.SLA[0], 'Longitude', 180)\n",
    "    new_shape = (160, 360)\n",
    "    lat_frac = new_measures.shape[0]/new_shape[0]\n",
    "    lon_frac = new_measures.shape[1]/new_shape[1]\n",
    "    binned_measures = bin_ndarray(new_measures, new_shape, operation='mean')\n",
    "    binned_measures = np.pad(binned_measures, ((10, 10), (0,0)), mode='constant', constant_values=(np.nan,))\n",
    "    print(\"Found MEaSUREs\")\n",
    "\n",
    "raws = [load_raw(RAW, plot_date, day) for day in n_days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin_diff, vmax_diff = -0.2, 0.2\n",
    "vmin_org, vmax_org = -0.7, 0.7\n",
    "cmap = 'jet'\n",
    "binned_data = []\n",
    "org_data = [processed.sla.data]\n",
    "diff_names = []\n",
    "org_names = [\"Ours\"]\n",
    "\n",
    "if binned_measures is not None:\n",
    "    binned_data.append(processed.sla.data - binned_measures)\n",
    "    org_data.append(binned_measures)\n",
    "    diff_names.append(\"Ours - MEaSUREs\")\n",
    "    org_names.append(\"MEaSUREs\")\n",
    "\n",
    "if binned_cmems is not None:\n",
    "    binned_data.append(processed.sla.data - binned_cmems)\n",
    "    org_data.append(binned_cmems)\n",
    "    diff_names.append(\"Ours - CMEMS\")\n",
    "    org_names.append(\"CMEMS\")\n",
    "\n",
    "if binned_measures is not None and binned_cmems is not None:\n",
    "    binned_data.append(binned_cmems - binned_measures)\n",
    "    org_data.append(\"Measures\")\n",
    "    diff_names.append(\"MEaSUREs - CMEMS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:18<00:00,  9.08s/it]\n"
     ]
    }
   ],
   "source": [
    "TD = 0.00005\n",
    "output_folder = Path('Difference')\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for binned, diff_name, org_name in zip(tqdm(binned_data[:-1]), diff_names[:-1], org_names[1:]):\n",
    "    mean_binned = np.nanmean(binned)\n",
    "    std_binned = np.nanstd(binned)\n",
    "    make_png(\n",
    "        image = binned - mean_binned,\n",
    "        figsize = (15*5, 5*5),\n",
    "        output_path = output_folder / f\"{date_to_processed(plot_date).name.replace('.nc', '')}_{TD*10000:.0f}_{org_name}.png\",\n",
    "        extent = [-180, 180, -90, 90],\n",
    "        vmin = -0.2,\n",
    "        vmax = 0.2,\n",
    "        title = f\"{diff_name} | {plot_date} | Time weighting = {TD}\",\n",
    "        cbar_label = \"SLA [m]\",\n",
    "        fontsize = 40,\n",
    "        ticksize = 40\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(diff_names) > 0:\n",
    "    fig, axes = plt.subplots(len(diff_names), 3, figsize=(24, 4*len(diff_names)), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "    for binned, diff_name, org_d, org_name, raw, n_day, ax in zip(tqdm(binned_data), diff_names, org_data, org_names, raws, n_days, axes):\n",
    "        \n",
    "        mean_binned = np.nanmean(binned)\n",
    "        std_binned = np.nanstd(binned)\n",
    "        imdiff = ax[0].imshow(binned - mean_binned, origin='lower', extent=get_extent(processed), vmin=vmin_diff, vmax=vmax_diff, cmap=cmap)\n",
    "        imorg = ax[1].imshow(org_d, origin='lower', extent=get_extent(processed), vmin=vmin_org, vmax=vmax_org, cmap=cmap)\n",
    "        ax[2].scatter(raw.lon, raw.lat, c=raw.sla, s=0.01, vmin=vmin_org, vmax=vmax_org, cmap=cmap)\n",
    "\n",
    "        plt.colorbar(imdiff, ax=ax[0])\n",
    "        plt.colorbar(imorg, ax=ax[1])\n",
    "        ax[0].set_title(f\"Mean removed {diff_name} (SLA). {mean_binned:.2f}±{std_binned:.2f}\")\n",
    "        ax[1].set_title(f\"{org_name} (SLA). {plot_date}\")\n",
    "        ax[2].set_title(f\"Raw (SLA). ±{n_day} days\")\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.coastlines()\n",
    "        ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n",
    "        ax.set_xticks([-180,-120, -60, 0, 60, 120, 180], crs=ccrs.PlateCarree())\n",
    "        ax.set_yticks([-90, -60, -30, 0, 30, 60, 90], crs=ccrs.PlateCarree())\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
